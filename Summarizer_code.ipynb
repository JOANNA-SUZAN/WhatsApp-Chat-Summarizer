{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "isH2_8A7BDoX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data1.txt', 'r', encoding='utf-8') as file:\n",
        "    data = file.read()\n",
        "\n",
        "pattern = r'\\d{1,2}/\\d{1,2}/\\d{2,4},\\s*\\d{1,2}:\\d{2}\\s*[APMapm]+ - '\n",
        "message = re.split(pattern, data)[1:]\n",
        "\n",
        "dates=re.findall(pattern, data)\n",
        "\n",
        "df=pd.DataFrame({'user_message':message,'message_date':dates})\n",
        "df.rename(columns={'message_date':'date'},inplace=True)\n",
        "\n",
        "user=[]\n",
        "messages=[]\n",
        "for message in df['user_message']:\n",
        "    entry=re.split('([\\w\\W]+?):\\s', message)\n",
        "    if entry[1:]:\n",
        "      if entry[2] != 'This message was deleted\\n' and entry[2]!=\"<Media omitted>\\n\":\n",
        "        user.append(entry[1])\n",
        "        str1=entry[1]\n",
        "        str2=entry[2]\n",
        "        res=str1+\" said \"+str2\n",
        "        messages.append(res)\n",
        "      else:\n",
        "        user.append('group_notification')\n",
        "        messages.append(entry[2])\n",
        "    else:\n",
        "        user.append('group_notification')\n",
        "        messages.append(entry[0])\n",
        "df['user']=user\n",
        "df['message']=messages\n",
        "df.drop(columns=['user_message'],inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pn66X_1BVcQ",
        "outputId": "77f509a9-40d0-4b26-bfab-75e1798dbacd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "<Media omitted>\n",
            "\n",
            "This message was deleted\n",
            "\n",
            "This message was deleted\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(input(\"Enter the number of recent chats to be summarized: \"))\n",
        "num = len(messages) - n\n",
        "msg = []\n",
        "\n",
        "for i in range(num, len(messages)):\n",
        "    if user[i] != 'group_notification':\n",
        "        str1 = [char for char in messages[i]]\n",
        "        str1[-1] = '.'\n",
        "        msg.append(str1)\n",
        "\n",
        "flat_msg = [char for sublist in msg for char in sublist]\n",
        "\n",
        "text = \"\".join(flat_msg)\n",
        "\n",
        "print(text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE304LqeB_Nb",
        "outputId": "c5ce8097-a924-4dc4-836c-960d345ab6a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of recent chats to be summarized: 50\n",
            "+91 99523 37618 said <Media omitted>.+91 99523 37618 said <Media omitted>.+91 99523 37618 said Dear Students, Make your report Writing Document and PPT ready by Tuesday (31-10-23) for submission and the presentation will be on Friday ( 3-11-23).  \n",
            "Report Writing Document - 15-20 pages \n",
            "Font-Times New Roman 13.+91 99523 37618 said <Media omitted>.+91 99523 37618 said Dear students, Kindly submit your individual work, the work related to your presentation in Moodle. Both word document and ppt slides that you prepared for the group Report Writing.+91 79760 09053 said Mam , The deadline in moodle is tomorrow 11pm , so is it okay for us to submit by tomorrow?.+91 99523 37618 said As informed earlier, submit it today..+91 79760 09053 said Mam , do we need to add only our contributions/content in word document?.+91 79760 09053 said Anyone ?.+91 99523 37618 said Only yours in Moodle.+91 98848 16256 said Ma'am I had a doubt, asked in pm,\n",
            "Kindly see.+91 70200 26145 said The presentation  on friday has to be of the whole report by the group or individual transcoding(analysis on responses from google form) presentation?.+91 99523 37618 said Meet me.+91 99523 37618 said in my cabin to clarify your doubt.+91 70200 26145 said Mam i came to your cabin.+91 98848 16256 said This message was deleted.+91 99523 37618 said https://docs.google.com/forms/d/e/1FAIpQLSe5-lCYmWu8MYN0Ixpq2jejBpH52atmpUW-4qK8XYg4AfyA6Q/viewform?usp=sf_link.+91 99523 37618 said This is the link for submitting your Presentation link. Only one submission from each group is required..+91 98848 16256 said Ma'am those who have presented also have to submit?.+91 99523 37618 said You have to upload a word document with the title of the presentation, group members list with reg. no. and the link for the video presentation..+91 99523 37618 said Those two groups can have the choice. It's not necessary to submit..+91 6383 041 453 said This message was deleted.+91 87144 34512 said Good afternoon ma’am\n",
            "Ma’am what all should we bring for fat lab ?.Kritika Eng said +1.+91 98848 16256 said Yes ma'am and what will we be asked to write in labFAT as well?.Dharani said +1.+91 81426 91499 said +1.+91 97129 58810 said +1.+91 70200 26145 said Also, are we supposed to write whole report  in lab fat?.+91 99523 37618 said Dear Students, Go through the whole report. You will be asked to write an analysis on the whole report. \n",
            "\n",
            "You can have a photocopy of the transcoding part (copy of the graphical chart for the questionnaire response without inference) for data reference.\n",
            "\n",
            "Only the hardcopy without inference will be allowed..+91 99523 37618 said Dear students, Bring the hardcopy of the important (atleast 10 questions) pie chart without inference for reference. \n",
            "\n",
            "You can take a colour printout if you wish to attach it in answer booklet instead of drawing it..+91 99523 37618 said No group work. So bring an individual copy to attach in the answer booklet.+91 87144 34512 said Mam when it comes to analysis what all should we write under it <This message was edited>.+91 99523 37618 said I will inform only in the class. You need to know your whole report writing..+91 87144 34512 said Okay mam.+91 99523 37618 said https://docs.google.com/forms/d/e/1FAIpQLSf71ux-_GSYeBTEzquSm_BnrQUBim8iVjYdrhRVe07Ukm4ugg/viewform?usp=sf_link.+91 99523 37618 said  Link for course outcome feedback....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentence_tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "    sentence_tokens = [[word for word in tokens if word.isalnum() and word not in stop_words] for tokens in sentence_tokens]\n",
        "    return sentence_tokens\n",
        "\n",
        "def calculate_similarity(sentence1, sentence2):\n",
        "    words1 = set(sentence1)\n",
        "    words2 = set(sentence2)\n",
        "    intersection = words1.intersection(words2)\n",
        "    union = words1.union(words2)\n",
        "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
        "\n",
        "def build_similarity_matrix(sentences):\n",
        "    sentence_tokens_array = np.array(sentences)\n",
        "\n",
        "    similarity_matrix = [[calculate_similarity(sentence1, sentence2) for sentence2 in sentence_tokens_array] for sentence1 in sentence_tokens_array]\n",
        "    return similarity_matrix\n",
        "\n",
        "def textrank_summarize(text, num_lines=10):\n",
        "    sentence_tokens = preprocess_text(text)\n",
        "    similarity_matrix = build_similarity_matrix(sentence_tokens)\n",
        "\n",
        "    graph = nx.from_numpy_array(np.array(similarity_matrix))\n",
        "\n",
        "    scores = nx.pagerank(graph)\n",
        "\n",
        "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentence_tokens)), reverse=True)\n",
        "\n",
        "    top_sentences = [sentence for score, sentence in ranked_sentences]\n",
        "\n",
        "    summary = ' '.join([' '.join(sentence) for sentence in top_sentences[:num_lines]])\n",
        "    return summary\n",
        "\n",
        "summary = textrank_summarize(text, num_lines=10)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzeeJ459Kj03",
        "outputId": "f4cd2fbd-b02e-46f8-8ecd-650a3a194382"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99523 37618 said dear students go whole report 99523 37618 said group work 99523 37618 said dear students make report writing document ppt ready tuesday submission presentation friday 99523 37618 said informed earlier submit today report writing document pages new roman 13 99523 37618 said dear students kindly submit individual work work related presentation moodle 99523 37618 said upload word document title presentation group members list reg 99523 37618 said two groups choice 99523 37618 said moodle 98848 16256 said doubt asked pm kindly see 70200 26145 said presentation friday whole report group individual transcoding analysis responses google form presentation 99523 37618 said dear students bring hardcopy important atleast 10 questions pie chart without inference reference 87144 34512 said okay mam 99523 37618 said https 99523 37618 said link course outcome feedback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-41-0f46d860bdd7>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sentence_tokens_array = np.array(sentences)\n"
          ]
        }
      ]
    }
  ]
}